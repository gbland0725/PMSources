{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 7,
   "id": "synthetic-chicken",
   "metadata": {},
   "outputs": [],
>>>>>>> parent of 29e74df (updated code)
   "source": [
    "%matplotlib inline\r\n",
    "import math\r\n",
    "import os \r\n",
    "import glob\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import matplotlib.colors as cl\r\n",
    "import matplotlib.ticker as mtick\r\n",
    "from matplotlib.gridspec import GridSpec\r\n",
    "import statsmodels.api as sm\r\n",
    "from pandas import ExcelWriter\r\n",
    "import pickle"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
   "source": [
    "#Read the csv file and modify columns. Returns a dataframe\r\n",
    "\r\n",
    "def tofread_csv(rawdata):\r\n",
    "    #read csv file.\r\n",
    "    data = pd.read_csv(rawdata, error_bad_lines=False)\r\n",
    "    #rennaming 1st column as ID\r\n",
    "    data = data.rename(index=str, columns={\"Unnamed: 0\": \"ID\"})\r\n",
    "    #drop columns that have volume and size\r\n",
    "    data = data[data.columns.drop(list(data.filter(regex='vol')))]\r\n",
    "    data = data[data.columns.drop(list(data.filter(regex='size')))]\r\n",
    "    data.columns = data.columns.str.replace('_mass_g','')\r\n",
    "    \r\n",
    "    data.drop(columns = ['Index', r'timestamp /s'], inplace = True)\r\n",
    "    data.columns = data.columns.str.replace(r' /g', '', regex = False)\r\n",
    "    data.columns = data.columns.str.replace(r'[', '', regex = False)\r\n",
    "    data.columns = data.columns.str.replace('+', '', regex = False)\r\n",
    "    data.columns = data.columns.str.replace(']', '', regex = False)\r\n",
    "    return data\r\n",
    "\r\n",
    "#non_zero_data drops rows that has a zero value in every isotope returning rows that have particle events. Should be ran first before starting other functions!\r\n",
    "def non_zero_data(data):\r\n",
    "    #data = data.drop(columns = \"ID\")\r\n",
    "    non_zero_rows = data.abs().sum(axis=1) > 0.0\r\n",
    "    non_zero_data = data[non_zero_rows]\r\n",
    "    #non_zero_columns = non_zero_data.abs().sum(axis=0) > 0.0\r\n",
    "    #non_zero_data = non_zero_data.loc[: , non_zero_columns]\r\n",
    "    return non_zero_data\r\n",
    "\r\n",
    "#wrap the tofread function\r\n",
    "def wrapper(string, ELEMENTS = None):\r\n",
    "    df = pd.DataFrame()\r\n",
    "    #ELEMENTS = 4\r\n",
    "    for i in glob.glob(string):\r\n",
    "        df = pd.concat([tofread_csv(i), df], axis = 0, sort = False)\r\n",
    "    if ELEMENTS != None:\r\n",
    "        df.drop(columns = ELEMENTS, inplace = True)\r\n",
    "    return non_zero_data(df)\r\n",
    "\r\n",
    "import copy\r\n",
    "\r\n",
    "#add noise to the data\r\n",
    "def addnoise(df, noise, coefficient = None):\r\n",
    "    if coefficient != None:\r\n",
    "        df = df*coefficient\r\n",
    "    df = df.fillna(0) + np.random.random(df.shape)*noise\r\n",
    "    return df\r\n",
    "\r\n",
    "#put multiple DFs together with the key\r\n",
    "def combineddf(dflist, dfkeys, ELEMENTS, noise = None, coefficient = None,):\r\n",
    "    #make an empty list\r\n",
    "    combinedlist = []\r\n",
    "    #make an empty dataframe\r\n",
    "    combineddf12 = pd.DataFrame()\r\n",
    "\r\n",
    "    for i,j in zip(dflist, dfkeys):\r\n",
    "        if noise == None and coefficient == None:\r\n",
    "            df = non_zero_data(i[ELEMENTS])\r\n",
    "            #fillnan with 0\r\n",
    "            df[np.isnan(df)] = 0\r\n",
    "        else:\r\n",
    "            #add noise\r\n",
    "            df = addnoise(i[ELEMENTS], noise, coefficient)\r\n",
    "\r\n",
    "\r\n",
    "        df['labels'] = j\r\n",
    "        combinedlist.append(df)\r\n",
    "        combineddf12 = pd.concat([combineddf12, df])\r\n",
    "    return combineddf12\r\n",
    "\r\n",
    "#return random projection codes for each sample\r\n",
    "def flyprojection(data, keys, ELEMENTS, expansionfactor):\r\n",
    "    data1 = combineddf(data, keys, ELEMENTS)\r\n",
    "    sourcenorm = copy.deepcopy(data1.iloc[:,:-1][ELEMENTS])\r\n",
    "\r\n",
    "    #had to center the mean like this because certain elements did not have any particle events for certain sources\r\n",
    "    for i in ELEMENTS:\r\n",
    "        sourcenorm[i] =sourcenorm[i].fillna(0)\r\n",
    "        try:\r\n",
    "            sourcenorm[i] = sourcenorm[i]/sourcenorm[i].mean(axis=0)\r\n",
    "        except ValueError:\r\n",
    "            continue\r\n",
    "    sourcenorm = sourcenorm.fillna(0)  \r\n",
    "    codes1 = encode(np.array(sourcenorm), expansionfactor)\r\n",
    "    return codes1\r\n",
    "\r\n",
    "#apply the cluster labels with corresponding max probability\r\n",
    "def applylabels(data, keys, ELEMENTS, model, codes):\r\n",
    "    data1 = combineddf(data, keys, ELEMENTS)\r\n",
    "    labelstransform = model.transform(codes)\r\n",
    "    data1['clusters'] = labelstransform.argmax(axis = 1)\r\n",
    "    data1['clustersprob'] = labelstransform.max(axis = 1)\r\n",
    "    return data1, labelstransform\r\n",
    "\r\n",
    "#Type: Data Frame. From a selected isotope and its particle events, select all other isotopes associated and drop others not associated with it\r\n",
    "def isotope_particle(data, isotope):\r\n",
    "    obs = data[data[isotope]>0.0]\r\n",
    "    return obs\r\n",
    "\r\n",
    "#counts the total particles associated to an isotope\r\n",
    "def conditional_particle(data, isotope):\r\n",
    "    obs = data[abs(data[isotope]) > 0.0].count()\r\n",
    "    return obs.sort_values(ascending=False)\r\n",
    "\r\n",
    "#returns aggregate particles of a dataset\r\n",
    "def aggregate_particles(data, element1 = None):\r\n",
    "    total = []\r\n",
    "    #go through each row\r\n",
    "    for i in data.itertuples():\r\n",
    "        labels = []\r\n",
    "        #in that row, go through each element\r\n",
    "        for j in range(1, len(i)):\r\n",
    "            #if there is some value\r\n",
    "            if i[j] > 0:\r\n",
    "                #append the element into the labels list\r\n",
    "                labels.append(data.columns[j - 1])\r\n",
    "                #if there is no elements\r\n",
    "                if labels[-1] == None:\r\n",
    "                    print('ERROR')\r\n",
    "        #if there are some elements in the labels list\r\n",
    "        if labels != []:\r\n",
    "            #append it to the total list\r\n",
    "            total.append(labels)\r\n",
    "    #make an array of this\r\n",
    "    total = np.array(total)\r\n",
    "    #only find the unique labels\r\n",
    "    uniquelist = np.unique(total)\r\n",
    "    \r\n",
    "    \r\n",
    "    #if element1 is there, focus on that one element\r\n",
    "    if element1 != None:\r\n",
    "        uniquelist = uniquelist[[element1 in i for i in uniquelist]]\r\n",
    "        \r\n",
    "    uniquelist1 = []\r\n",
    "    #for each unique label\r\n",
    "    for i in uniquelist:\r\n",
    "        #join them together with a + sign\r\n",
    "        uniquelist1.append('+'.join(i))\r\n",
    "    totalvalue = []\r\n",
    "    # for each unique label\r\n",
    "    for i in uniquelist:\r\n",
    "        value = 0\r\n",
    "        # for each label in total\r\n",
    "        for j in total:\r\n",
    "            if i == j:\r\n",
    "                #count how many there are\r\n",
    "                value = value + 1\r\n",
    "        totalvalue.append(value)\r\n",
    "\r\n",
    "    finaldf = pd.DataFrame(totalvalue, uniquelist1, columns = ['Value']).sort_values('Value', ascending = False)\r\n",
    "    return finaldf\r\n",
    "\r\n",
    "#Counts total number of peaks for each isotope\r\n",
    "def marginal_particle(data):\r\n",
    "    #replace 0 with nan\r\n",
    "    data.replace(0, np.nan, inplace = True)\r\n",
    "    return abs(data).count().sort_values(ascending=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#import the data\r\n",
    "DROPELEMENTS = ['28Si', '29Si', '56Fe', '24Mg', '25Mg', '27Al']\r\n",
    "\r\n",
    "\r\n",
    "#heating\r\n",
    "Q16_12_10 = wrapper('sample_data/particle_masses_16_12_10**', DROPELEMENTS)\r\n",
    "Q16_12_11 = wrapper('sample_data/particle_masses_16_12_11**', DROPELEMENTS)\r\n",
    "Q16_12_12 = wrapper('sample_data/particle_masses_16_12_12**', DROPELEMENTS)\r\n",
    "Q16_12_13 = wrapper('sample_data/particle_masses_16_12_13**', DROPELEMENTS)\r\n",
    "Q16_12_14 = wrapper('sample_data/particle_masses_16_12_14**', DROPELEMENTS)\r\n",
    "Q16_12_15 = wrapper('sample_data/particle_masses_16_12_15**', DROPELEMENTS)\r\n",
    "Q16_12_16 = wrapper('sample_data/particle_masses_16_12_16**', DROPELEMENTS)\r\n",
    "Q16_12_17 = wrapper('sample_data/particle_masses_16_12_17**', DROPELEMENTS)\r\n",
    "Q16_12_18 = wrapper('sample_data/particle_masses_16_12_18**', DROPELEMENTS)\r\n",
    "Q16_12_19 = wrapper('sample_data/particle_masses_16_12_19**', DROPELEMENTS)\r\n",
    "Q16_12_20 = wrapper('sample_data/particle_masses_16_12_20**', DROPELEMENTS)\r\n",
    "Q16_12_21 = wrapper('sample_data/particle_masses_16_12_21**', DROPELEMENTS)\r\n",
    "Q16_12_22 = wrapper('sample_data/particle_masses_16_12_22**', DROPELEMENTS)\r\n",
    "\r\n",
    "Qian2016 = [Q16_12_10, Q16_12_11, Q16_12_12, Q16_12_13, Q16_12_14, Q16_12_15, Q16_12_16, Q16_12_17, Q16_12_18, Q16_12_19, Q16_12_20, Q16_12_21, Q16_12_22]\r\n",
    "Qian2016keys = ['Q16_12_10', 'Q16_12_11', 'Q16_12_12', 'Q16_12_13', 'Q16_12_14', 'Q16_12_15', 'Q16_12_16', 'Q16_12_17', 'Q16_12_18', 'Q16_12_19', 'Q16_12_20', 'Q16_12_21', 'Q16_12_22']\r\n",
    "\r\n",
    "\r\n",
    "#Nonheating\r\n",
    "Q18_03_06 = wrapper('sample_data/particle_masses_18_03_06**', DROPELEMENTS)\r\n",
    "Q18_03_07 = wrapper('sample_data/particle_masses_18_03_07**', DROPELEMENTS)\r\n",
    "Q18_03_08 = wrapper('sample_data/particle_masses_18_03_08**', DROPELEMENTS)\r\n",
    "Q18_03_09 = wrapper('sample_data/particle_masses_18_03_09**', DROPELEMENTS)\r\n",
    "Q18_03_10 = wrapper('sample_data/particle_masses_18_03_10**', DROPELEMENTS)\r\n",
    "Q18_03_11 = wrapper('sample_data/particle_masses_18_03_11**', DROPELEMENTS)\r\n",
    "Q18_03_12 = wrapper('sample_data/particle_masses_18_03_12**', DROPELEMENTS)\r\n",
    "Q18_03_13 = wrapper('sample_data/particle_masses_18_03_13**', DROPELEMENTS)\r\n",
    "Q18_03_14 = wrapper('sample_data/particle_masses_18_03_14**', DROPELEMENTS)\r\n",
    "Q18_03_15 = wrapper('sample_data/particle_masses_18_03_15**', DROPELEMENTS)\r\n",
    "\r\n",
    "Qian2018 = [Q18_03_06, Q18_03_07, Q18_03_08, Q18_03_09, Q18_03_10, Q18_03_11, Q18_03_12, Q18_03_13, Q18_03_14, Q18_03_15]\r\n",
    "Qian2018keys = ['Q18_03_06', 'Q18_03_07', 'Q18_03_08', 'Q18_03_09', 'Q18_03_10', 'Q18_03_11', 'Q18_03_12', 'Q18_03_13', 'Q18_03_14', 'Q18_03_15']\r\n",
    "\r\n",
    "\r\n",
    "#Urban\r\n",
    "QU18_12_02 = wrapper('sample_data/particle_masses_U18_12_02**', DROPELEMENTS)\r\n",
    "QU18_12_06 = wrapper('sample_data/particle_masses_U18_12_06**', DROPELEMENTS)\r\n",
    "QU18_12_13 = wrapper('sample_data/particle_masses_U18_12_13**', DROPELEMENTS)\r\n",
    "QU18_12_14 = wrapper('sample_data/particle_masses_U18_12_14**', DROPELEMENTS)\r\n",
    "QU18_12_18 = wrapper('sample_data/particle_masses_U18_12_18**', DROPELEMENTS)\r\n",
    "QU18_12_26 = wrapper('sample_data/particle_masses_U18_12_26**', DROPELEMENTS)\r\n",
    "QU18_12_28 = wrapper('sample_data/particle_masses_U18_12_28**', DROPELEMENTS)\r\n",
    "QU19_01_02 = wrapper('sample_data/particle_masses_U19_01_02**', DROPELEMENTS)\r\n",
    "\r\n",
    "QianU2019 = [QU18_12_02, QU18_12_06, QU18_12_13, QU18_12_14, QU18_12_18, QU18_12_26, QU18_12_28, QU19_01_02]\r\n",
    "QianU2019keys = ['QU18_12_02', 'QU18_12_06', 'QU18_12_13', 'QU18_12_14', 'QU18_12_18', 'QU18_12_26', 'QU18_12_28', 'QU19_01_02']\r\n",
    "\r\n",
    "\r\n",
    "#Rural\r\n",
    "QR18_12_02 = wrapper('sample_data/particle_masses_R18_12_02**', DROPELEMENTS)\r\n",
    "QR18_12_06 = wrapper('sample_data/particle_masses_R18_12_05**', DROPELEMENTS)\r\n",
    "QR18_12_13 = wrapper('sample_data/particle_masses_R18_12_13**', DROPELEMENTS)\r\n",
    "QR18_12_14 = wrapper('sample_data/particle_masses_R18_12_14**', DROPELEMENTS)\r\n",
    "QR18_12_18 = wrapper('sample_data/particle_masses_R18_12_18**', DROPELEMENTS)\r\n",
    "QR18_12_26 = wrapper('sample_data/particle_masses_R18_12_26**', DROPELEMENTS)\r\n",
    "QR18_12_28 = wrapper('sample_data/particle_masses_R18_12_28**', DROPELEMENTS)\r\n",
    "QR19_01_02 = wrapper('sample_data/particle_masses_R19_01_02**', DROPELEMENTS)\r\n",
    "\r\n",
    "QianR2019 = [QR18_12_02, QR18_12_06, QR18_12_13, QR18_12_14, QR18_12_18, QR18_12_26, QR18_12_28, QR19_01_02]\r\n",
    "QianR2019keys = ['QR18_12_02', 'QR18_12_06', 'QR18_12_13', 'QR18_12_14', 'QR18_12_18', 'QR18_12_26', 'QR18_12_28', 'QR19_01_02']\r\n",
    "\r\n",
    "\r\n",
    "#source samples\r\n",
    "soildust = wrapper('sample_data/particle_masses_Source1**', DROPELEMENTS)\r\n",
    "condust = wrapper('sample_data/particle_masses_Source2**', DROPELEMENTS)\r\n",
    "condsand = wrapper('sample_data/particle_masses_Source3**', DROPELEMENTS)\r\n",
    "coalburning = wrapper('sample_data/particle_masses_Source4**', DROPELEMENTS)\r\n",
    "indemission = wrapper('sample_data/particle_masses_Source5**', DROPELEMENTS)\r\n",
    "urbanfugdust = wrapper('sample_data/particle_masses_Source6**', DROPELEMENTS)\r\n",
    "\r\n",
    "Carexhaust = wrapper('sample_data/particle_masses_car**', DROPELEMENTS)\r\n",
    "biomass = wrapper('sample_data/particle_masses_biomass**', DROPELEMENTS)\r\n",
    "\r\n",
    "#drop duplicate columns\r\n",
    "Carexhaust = Carexhaust.loc[:,~Carexhaust.columns.duplicated()]\r\n",
    "biomass = biomass.loc[:,~biomass.columns.duplicated()]\r\n",
    "\r\n",
    "\r\n",
    "Sourcesamples = [soildust, condust, condsand, coalburning, indemission, Carexhaust, biomass]\r\n",
    "Sourcekeys = ['Soil dust', 'Construction dust', 'Construction sand', 'Coal burning', 'Industrial emission', 'Car exhaust', 'Biomass']\r\n",
    "\r\n",
    "\r\n",
    "#blanks\r\n",
    "blank1 = wrapper('sample_data/particle_masses_blank 1**', DROPELEMENTS)\r\n",
    "blank2 = wrapper('sample_data/particle_masses_blank 2**', DROPELEMENTS)\r\n",
    "blank3 = wrapper('sample_data/particle_masses_blank 3**', DROPELEMENTS)\r\n",
    "blank4 = wrapper('sample_data/particle_masses_blank 4**', DROPELEMENTS)\r\n",
    "blank5 = wrapper('sample_data/particle_masses_blank 5**', DROPELEMENTS)\r\n",
    "\r\n",
    "blank = [blank1, blank2, blank3, blank4, blank5]\r\n",
    "blankkeys = ['blank1', 'blank2', 'blank3', 'blank4', 'blank5']\r\n",
    "\r\n",
    "PPFilter1 = wrapper('sample_data/particle_masses_PP Filter 1**', DROPELEMENTS)\r\n",
    "PPFilter2 = wrapper('sample_data/particle_masses_PP Filter 2**', DROPELEMENTS)\r\n",
    "QuartzFilter1 = wrapper('sample_data/particle_masses_Quartz Filter 1**', DROPELEMENTS)\r\n",
    "QuartzFilter2 = wrapper('sample_data/particle_masses_Quartz Filter 2**', DROPELEMENTS)\r\n",
    "\r\n",
    "Filterblank = [PPFilter1, PPFilter2, QuartzFilter1, QuartzFilter2]\r\n",
    "Filterblankkeys = ['PPFilter1', 'PPFilter2', 'QuartzFilter1', 'QuartzFilter2']\r\n",
    "\r\n",
    "airkeys = [Qian2016keys, Qian2018keys, QianU2019keys, QianR2019keys, Sourcekeys]\r\n",
    "airsection = ['Heating', 'Non-Heating', 'Urban', 'Rural', 'Sources']\r\n",
    "airsamples = [Qian2016, Qian2018, QianU2019, QianR2019, Sourcesamples]\r\n",
    "\r\n",
    "\r\n",
    "ELEMENTS = ['48Ti', '53Cr', '55Mn', '54Fe', '59Co', '60Ni', '63Cu', '64Zn', '69Ga', '72Ge', '75As', '78Se', '85Rb', '88Sr', '89Y', '90Zr', '93Nb', \r\n",
    "           '98Mo', '108Pd', '107Ag', '114Cd', '120Sn', '121Sb', '133Cs', '138Ba', '139La', '140Ce', '152Sm', '153Eu', '158Gd', '159Tb', '164Dy', '165Ho',\r\n",
    "           '166Er', '169Tm', '174Yb', '175Lu', '180Hf', '185Re', '192Os', '193Ir', '195Pt', '197Au', '202Hg', '208Pb', '238U', '51V']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
=======
   "execution_count": 8,
   "id": "deluxe-scheme",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the csv file and modify columns. Returns a dataframe\n",
    "def tofread_csv(rawdata):\n",
    "    #read csv file.\n",
    "    data = pd.read_csv(rawdata, error_bad_lines=False)\n",
    "    #rennaming 1st column as ID\n",
    "    data = data.rename(index=str, columns={\"Unnamed: 0\": \"ID\"})\n",
    "    #drop columns that have volume and size\n",
    "    data = data[data.columns.drop(list(data.filter(regex='vol')))]\n",
    "    data = data[data.columns.drop(list(data.filter(regex='size')))]\n",
    "    data.columns = data.columns.str.replace('_mass_g','')\n",
    "    return data\n",
    "\n",
    "#non_zero_data drops rows that has a zero value in every isotope returning rows that have particle events. Should be ran first before starting other functions!\n",
    "def non_zero_data(data):\n",
    "    #data = data.drop(columns = \"ID\")\n",
    "    non_zero_rows = data.abs().sum(axis=1) > 0.0\n",
    "    non_zero_data = data[non_zero_rows]\n",
    "    #non_zero_columns = non_zero_data.abs().sum(axis=0) > 0.0\n",
    "    #non_zero_data = non_zero_data.loc[: , non_zero_columns]\n",
    "    return non_zero_data\n",
    "\n",
    "#wrap the tofread function\n",
    "def wrapper(string, ELEMENTS = None):\n",
    "    df = pd.DataFrame()\n",
    "    #ELEMENTS = 4\n",
    "    for i in glob.glob(string):\n",
    "        df = pd.concat([tofread_csv(i), df], axis = 0, sort = False)\n",
    "    df.drop(columns = ['Index', r'timestamp /s'], inplace = True)\n",
    "    df.columns = df.columns.str.replace(r' /g', '')\n",
    "    df.columns = df.columns.str.replace(r'[', '')\n",
    "    df.columns = df.columns.str.replace('+', '')\n",
    "    df.columns = df.columns.str.replace(']', '')\n",
    "    if ELEMENTS != None:\n",
    "        df.drop(columns = ELEMENTS, inplace = True)\n",
    "    return non_zero_data(df)\n",
    "\n",
    "import copy\n",
    "\n",
    "#add noise to the data\n",
    "def addnoise(df, noise, coefficient = None):\n",
    "    if coefficient != None:\n",
    "        df = df*coefficient\n",
    "    df = df.fillna(0) + np.random.random(df.shape)*noise\n",
    "    return df\n",
    "\n",
    "#put multiple DFs together with the key\n",
    "def combineddf(dflist, dfkeys, ELEMENTS, noise = None, coefficient = None,):\n",
    "    #make an empty list\n",
    "    combinedlist = []\n",
    "    #make an empty dataframe\n",
    "    combineddf12 = pd.DataFrame()\n",
    "\n",
    "    for i,j in zip(dflist, dfkeys):\n",
    "        if noise == None and coefficient == None:\n",
    "            df = non_zero_data(i[ELEMENTS])\n",
    "            #fillnan with 0\n",
    "            df[np.isnan(df)] = 0\n",
    "        else:\n",
    "            #add noise\n",
    "            df = addnoise(i[ELEMENTS], noise, coefficient)\n",
    "\n",
    "\n",
    "        df['labels'] = j\n",
    "        combinedlist.append(df)\n",
    "        combineddf12 = pd.concat([combineddf12, df])\n",
    "    return combineddf12\n",
    "\n",
    "#return random projection codes for each sample\n",
    "def flyprojection(data, keys, ELEMENTS, expansionfactor):\n",
    "    data1 = combineddf(data, keys, ELEMENTS)\n",
    "    sourcenorm = copy.deepcopy(data1.iloc[:,:-1][ELEMENTS])\n",
    "\n",
    "    #had to center the mean like this because certain elements did not have any particle events for certain sources\n",
    "    for i in ELEMENTS:\n",
    "        sourcenorm[i] =sourcenorm[i].fillna(0)\n",
    "        try:\n",
    "            sourcenorm[i] = sourcenorm[i]/sourcenorm[i].mean(axis=0)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    sourcenorm = sourcenorm.fillna(0)  \n",
    "    codes1 = encode(np.array(sourcenorm), expansionfactor)\n",
    "    return codes1\n",
    "\n",
    "#apply the cluster labels with corresponding max probability\n",
    "def applylabels(data, keys, ELEMENTS, model, codes):\n",
    "    data1 = combineddf(data, keys, ELEMENTS)\n",
    "    labelstransform = model.transform(codes)\n",
    "    data1['clusters'] = labelstransform.argmax(axis = 1)\n",
    "    data1['clustersprob'] = labelstransform.max(axis = 1)\n",
    "    return data1, labelstransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "numerical-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the data\n",
    "DROPELEMENTS = ['28Si', '29Si', '56Fe', '24Mg', '25Mg', '27Al']\n",
    "\n",
    "\n",
    "#heating\n",
    "Q16_12_10 = wrapper('sample_data/particle_masses_16_12_10**', DROPELEMENTS)\n",
    "Q16_12_11 = wrapper('sample_data/particle_masses_16_12_11**', DROPELEMENTS)\n",
    "Q16_12_12 = wrapper('sample_data/particle_masses_16_12_12**', DROPELEMENTS)\n",
    "Q16_12_13 = wrapper('sample_data/particle_masses_16_12_13**', DROPELEMENTS)\n",
    "Q16_12_14 = wrapper('sample_data/particle_masses_16_12_14**', DROPELEMENTS)\n",
    "Q16_12_15 = wrapper('sample_data/particle_masses_16_12_15**', DROPELEMENTS)\n",
    "Q16_12_16 = wrapper('sample_data/particle_masses_16_12_16**', DROPELEMENTS)\n",
    "Q16_12_17 = wrapper('sample_data/particle_masses_16_12_17**', DROPELEMENTS)\n",
    "Q16_12_18 = wrapper('sample_data/particle_masses_16_12_18**', DROPELEMENTS)\n",
    "Q16_12_19 = wrapper('sample_data/particle_masses_16_12_19**', DROPELEMENTS)\n",
    "Q16_12_20 = wrapper('sample_data/particle_masses_16_12_20**', DROPELEMENTS)\n",
    "Q16_12_21 = wrapper('sample_data/particle_masses_16_12_21**', DROPELEMENTS)\n",
    "Q16_12_22 = wrapper('sample_data/particle_masses_16_12_22**', DROPELEMENTS)\n",
    "\n",
    "Qian2016 = [Q16_12_10, Q16_12_11, Q16_12_12, Q16_12_13, Q16_12_14, Q16_12_15, Q16_12_16, Q16_12_17, Q16_12_18, Q16_12_19, Q16_12_20, Q16_12_21, Q16_12_22]\n",
    "Qian2016keys = ['Q16_12_10', 'Q16_12_11', 'Q16_12_12', 'Q16_12_13', 'Q16_12_14', 'Q16_12_15', 'Q16_12_16', 'Q16_12_17', 'Q16_12_18', 'Q16_12_19', 'Q16_12_20', 'Q16_12_21', 'Q16_12_22']\n",
    "\n",
    "\n",
    "#Nonheating\n",
    "Q18_03_06 = wrapper('sample_data/particle_masses_18_03_06**', DROPELEMENTS)\n",
    "Q18_03_07 = wrapper('sample_data/particle_masses_18_03_07**', DROPELEMENTS)\n",
    "Q18_03_08 = wrapper('sample_data/particle_masses_18_03_08**', DROPELEMENTS)\n",
    "Q18_03_09 = wrapper('sample_data/particle_masses_18_03_09**', DROPELEMENTS)\n",
    "Q18_03_10 = wrapper('sample_data/particle_masses_18_03_10**', DROPELEMENTS)\n",
    "Q18_03_11 = wrapper('sample_data/particle_masses_18_03_11**', DROPELEMENTS)\n",
    "Q18_03_12 = wrapper('sample_data/particle_masses_18_03_12**', DROPELEMENTS)\n",
    "Q18_03_13 = wrapper('sample_data/particle_masses_18_03_13**', DROPELEMENTS)\n",
    "Q18_03_14 = wrapper('sample_data/particle_masses_18_03_14**', DROPELEMENTS)\n",
    "Q18_03_15 = wrapper('sample_data/particle_masses_18_03_15**', DROPELEMENTS)\n",
    "\n",
    "Qian2018 = [Q18_03_06, Q18_03_07, Q18_03_08, Q18_03_09, Q18_03_10, Q18_03_11, Q18_03_12, Q18_03_13, Q18_03_14, Q18_03_15]\n",
    "Qian2018keys = ['Q18_03_06', 'Q18_03_07', 'Q18_03_08', 'Q18_03_09', 'Q18_03_10', 'Q18_03_11', 'Q18_03_12', 'Q18_03_13', 'Q18_03_14', 'Q18_03_15']\n",
    "\n",
    "\n",
    "#Urban\n",
    "QU18_12_02 = wrapper('sample_data/particle_masses_U18_12_02**', DROPELEMENTS)\n",
    "QU18_12_06 = wrapper('sample_data/particle_masses_U18_12_06**', DROPELEMENTS)\n",
    "QU18_12_13 = wrapper('sample_data/particle_masses_U18_12_13**', DROPELEMENTS)\n",
    "QU18_12_14 = wrapper('sample_data/particle_masses_U18_12_14**', DROPELEMENTS)\n",
    "QU18_12_18 = wrapper('sample_data/particle_masses_U18_12_18**', DROPELEMENTS)\n",
    "QU18_12_26 = wrapper('sample_data/particle_masses_U18_12_26**', DROPELEMENTS)\n",
    "QU18_12_28 = wrapper('sample_data/particle_masses_U18_12_28**', DROPELEMENTS)\n",
    "QU19_01_02 = wrapper('sample_data/particle_masses_U19_01_02**', DROPELEMENTS)\n",
    "\n",
    "QianU2019 = [QU18_12_02, QU18_12_06, QU18_12_13, QU18_12_14, QU18_12_18, QU18_12_26, QU18_12_28, QU19_01_02]\n",
    "QianU2019keys = ['QU18_12_02', 'QU18_12_06', 'QU18_12_13', 'QU18_12_14', 'QU18_12_18', 'QU18_12_26', 'QU18_12_28', 'QU19_01_02']\n",
    "\n",
    "\n",
    "#Rural\n",
    "QR18_12_02 = wrapper('sample_data/particle_masses_R18_12_02**', DROPELEMENTS)\n",
    "QR18_12_06 = wrapper('sample_data/particle_masses_R18_12_05**', DROPELEMENTS)\n",
    "QR18_12_13 = wrapper('sample_data/particle_masses_R18_12_13**', DROPELEMENTS)\n",
    "QR18_12_14 = wrapper('sample_data/particle_masses_R18_12_14**', DROPELEMENTS)\n",
    "QR18_12_18 = wrapper('sample_data/particle_masses_R18_12_18**', DROPELEMENTS)\n",
    "QR18_12_26 = wrapper('sample_data/particle_masses_R18_12_26**', DROPELEMENTS)\n",
    "QR18_12_28 = wrapper('sample_data/particle_masses_R18_12_28**', DROPELEMENTS)\n",
    "QR19_01_02 = wrapper('sample_data/particle_masses_R19_01_02**', DROPELEMENTS)\n",
    "\n",
    "QianR2019 = [QR18_12_02, QR18_12_06, QR18_12_13, QR18_12_14, QR18_12_18, QR18_12_26, QR18_12_28, QR19_01_02]\n",
    "QianR2019keys = ['QR18_12_02', 'QR18_12_06', 'QR18_12_13', 'QR18_12_14', 'QR18_12_18', 'QR18_12_26', 'QR18_12_28', 'QR19_01_02']\n",
    "\n",
    "\n",
    "#source samples\n",
    "soildust = wrapper('sample_data/particle_masses_Source1**', DROPELEMENTS)\n",
    "condust = wrapper('sample_data/particle_masses_Source2**', DROPELEMENTS)\n",
    "condsand = wrapper('sample_data/particle_masses_Source3**', DROPELEMENTS)\n",
    "coalburning = wrapper('sample_data/particle_masses_Source4**', DROPELEMENTS)\n",
    "indemission = wrapper('sample_data/particle_masses_Source5**', DROPELEMENTS)\n",
    "urbanfugdust = wrapper('sample_data/particle_masses_Source6**', DROPELEMENTS)\n",
    "\n",
    "Carexhaust = wrapper('sample_data/particle_masses_car**', DROPELEMENTS)\n",
    "biomass = wrapper('sample_data/particle_masses_biomass**', DROPELEMENTS)\n",
    "\n",
    "#drop duplicate columns\n",
    "Carexhaust = Carexhaust.loc[:,~Carexhaust.columns.duplicated()]\n",
    "biomass = biomass.loc[:,~biomass.columns.duplicated()]\n",
    "\n",
    "\n",
    "Sourcesamples = [soildust, condust, condsand, coalburning, indemission, Carexhaust, biomass]\n",
    "Sourcekeys = ['Soil dust', 'Construction dust', 'Construction sand', 'Coal burning', 'Industrial emission', 'Car exhaust', 'Biomass']\n",
    "\n",
    "\n",
    "#blanks\n",
    "blank1 = wrapper('sample_data/particle_masses_blank 1**', DROPELEMENTS)\n",
    "blank2 = wrapper('sample_data/particle_masses_blank 2**', DROPELEMENTS)\n",
    "blank3 = wrapper('sample_data/particle_masses_blank 3**', DROPELEMENTS)\n",
    "blank4 = wrapper('sample_data/particle_masses_blank 4**', DROPELEMENTS)\n",
    "blank5 = wrapper('sample_data/particle_masses_blank 5**', DROPELEMENTS)\n",
    "\n",
    "blank = [blank1, blank2, blank3, blank4, blank5]\n",
    "blankkeys = ['blank1', 'blank2', 'blank3', 'blank4', 'blank5']\n",
    "\n",
    "PPFilter1 = wrapper('sample_data/particle_masses_PP Filter 1**', DROPELEMENTS)\n",
    "PPFilter2 = wrapper('sample_data/particle_masses_PP Filter 2**', DROPELEMENTS)\n",
    "QuartzFilter1 = wrapper('sample_data/particle_masses_Quartz Filter 1**', DROPELEMENTS)\n",
    "QuartzFilter2 = wrapper('sample_data/particle_masses_Quartz Filter 2**', DROPELEMENTS)\n",
    "\n",
    "Filterblank = [PPFilter1, PPFilter2, QuartzFilter1, QuartzFilter2]\n",
    "Filterblankkeys = ['PPFilter1', 'PPFilter2', 'QuartzFilter1', 'QuartzFilter2']\n",
    "\n",
    "airkeys = [Qian2016keys, Qian2018keys, QianU2019keys, QianR2019keys, Sourcekeys]\n",
    "airsection = ['Heating', 'Non-Heating', 'Urban', 'Rural', 'Sources']\n",
    "airsamples = [Qian2016, Qian2018, QianU2019, QianR2019, Sourcesamples]\n",
    "\n",
    "\n",
    "ELEMENTS = ['48Ti', '53Cr', '55Mn', '54Fe', '59Co', '58Ni', '63Cu', '64Zn', '69Ga', '72Ge', '75As', '78Se', '85Rb', '88Sr', '89Y', '90Zr', '93Nb', \n",
    "           '98Mo', '108Pd', '107Ag', '114Cd', '120Sn', '121Sb', '130Te', '133Cs', '138Ba', '139La', '140Ce', '152Sm', '153Eu', '158Gd', '159Tb', '164Dy', '165Ho',\n",
    "           '166Er', '169Tm', '174Yb', '175Lu', '180Hf', '185Re', '192Os', '193Ir', '195Pt', '197Au', '202Hg', '208Pb', '238U', '51V']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "assigned-scientist",
   "metadata": {},
   "outputs": [],
>>>>>>> parent of 29e74df (updated code)
   "source": [
    "#set each to the specific ELEMENTS\r\n",
    "soildust = non_zero_data(soildust[ELEMENTS])\r\n",
    "condust = non_zero_data(condust[ELEMENTS])\r\n",
    "condsand = non_zero_data(condsand[ELEMENTS])\r\n",
    "coalburning = non_zero_data(coalburning[ELEMENTS])\r\n",
    "indemission = non_zero_data(indemission[ELEMENTS])\r\n",
    "urbanfugdust = non_zero_data(urbanfugdust[ELEMENTS])\r\n",
    "Carexhaust = non_zero_data(Carexhaust[ELEMENTS])\r\n",
    "biomass = non_zero_data(biomass[ELEMENTS])\r\n",
    "\r\n",
    "#reset all the indices\r\n",
    "soildust.reset_index(inplace = True, drop = True)\r\n",
    "condust.reset_index(inplace = True, drop = True)\r\n",
    "condsand.reset_index(inplace = True, drop = True)\r\n",
    "coalburning.reset_index(inplace = True, drop = True)\r\n",
    "indemission.reset_index(inplace = True, drop = True)\r\n",
    "urbanfugdust.reset_index(inplace = True, drop = True)\r\n",
    "Carexhaust.reset_index(inplace = True, drop = True)\r\n",
    "biomass.reset_index(inplace = True, drop = True)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
=======
   "id": "clear-pharmacology",
   "metadata": {},
>>>>>>> parent of 29e74df (updated code)
   "source": [
    "# merging all labels together"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 11,
   "id": "quality-cemetery",
   "metadata": {},
   "outputs": [],
>>>>>>> parent of 29e74df (updated code)
   "source": [
    "#merge soil and condust and consand altogether\r\n",
    "\r\n",
    "soilcon = pd.concat([soildust, condust, condsand])\r\n",
    "\r\n",
    "Sourcesamples = [soilcon, coalburning, indemission, Carexhaust, biomass]\r\n",
    "Sourcekeys = ['Soil and Construction', 'Coal burning', 'Industrial emission', 'Car exhaust', 'Biomass']\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 12,
   "id": "accurate-focus",
   "metadata": {},
   "outputs": [],
>>>>>>> parent of 29e74df (updated code)
   "source": [
    "#create a list with same amount of particles for each\r\n",
    "Sourcesamplessame = []\r\n",
    "for i in Sourcesamples:\r\n",
    "    Sourcesamplessame.append(i.sample(np.array([len(i) for i in Sourcesamples]).min(), random_state = 1))\r\n",
    "\r\n",
    "#reset the index\r\n",
    "for i in Sourcesamplessame:\r\n",
    "    i.reset_index(inplace = True, drop = True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
   "source": [
    "def split_data(data, percent):\r\n",
    "    data_percent = data.iloc[data.sample(frac = percent, random_state = 5).index]\r\n",
    "    data_rest = data.loc[~data.index.isin(data_percent.index)]\r\n",
    "    return data_percent, data_rest\r\n",
    "\r\n",
    "Sourcesamples_training = []\r\n",
    "Sourcesamples_testing = []\r\n",
    "\r\n",
    "for i in Sourcesamplessame:\r\n",
    "    train, test = split_data(i, 0.8)\r\n",
    "    Sourcesamples_training.append(train)\r\n",
=======
   "execution_count": 13,
   "id": "bridal-manhattan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2333, 2333, 2333, 2333, 2333]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(i) for i in Sourcesamplessame]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "laden-input",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, percent):\n",
    "    data_percent = data.iloc[data.sample(frac = percent).index]\n",
    "    data_rest = data.loc[~data.index.isin(data_percent.index)]\n",
    "    return data_percent, data_rest\n",
    "\n",
    "Sourcesamples_training = []\n",
    "Sourcesamples_testing = []\n",
    "\n",
    "for i in Sourcesamplessame:\n",
    "    train, test = split_data(i, 0.8)\n",
    "    Sourcesamples_training.append(train)\n",
>>>>>>> parent of 29e74df (updated code)
    "    Sourcesamples_testing.append(test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 15,
   "id": "orange-sheep",
   "metadata": {},
   "outputs": [],
>>>>>>> parent of 29e74df (updated code)
   "source": [
    "rng = np.random.default_rng(seed = 1000)\r\n",
    "\r\n",
    "d = len(ELEMENTS)  # number of features\r\n",
    "expansion_factor = 128\r\n",
    "m = expansion_factor * d  # dimension of the code space\r\n",
    "\r\n",
    "def top_idx(a, k):\r\n",
    "    \"\"\"indices of the top k values of each row of a\"\"\"\r\n",
    "    return np.argpartition(a, -k)[:, -k:]\r\n",
    "\r\n",
    "def top_mask(a, k):\r\n",
    "    \"\"\"create a boolean matrix the same shape as a indicating the top k items of each row\"\"\"\r\n",
    "    idx = top_idx(a, k)\r\n",
    "    mask = np.zeros_like(a)\r\n",
    "    row_idx = np.arange(len(a)).reshape(-1,1)\r\n",
    "    mask[np.repeat(row_idx, k, axis=-1), idx] = 1\r\n",
    "    return mask\r\n",
    "\r\n",
    "# from the supplementary materials:\r\n",
    "# A simple model of M is a sparse, binary random matrix:\r\n",
    "# each entry M_ij is set independently with probability p. Choosingp= 6/d, for instance,\r\n",
    "# would mean that each row of M has roughly 6 entries equal to 1 (and all of the other\r\n",
    "# entries are 0), which matches experimental findings.\r\n",
    "p = 8 / float(d)\r\n",
    "# M is the random mapping from features to codes (in the supplementary materials it is a m x d matrix),\r\n",
    "# here it is swapped so we can do data * M = codes where data is n samples x d and codes in n samples x m\r\n",
    "M = (rng.random(size=(d, m)) < p).astype(np.uint8)\r\n",
    "\r\n",
    "def encode(data, k):\r\n",
    "    \"\"\"Encode the data using random projection and winner take all approach \"\"\"\r\n",
    "    res = data @ M\r\n",
    "    mask = top_mask(res, k)\r\n",
    "    return res * mask"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 16,
   "id": "complex-korea",
   "metadata": {},
   "outputs": [],
>>>>>>> parent of 29e74df (updated code)
   "source": [
    "k = 9 # the k largest values of the code will be used as the result\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 17,
   "id": "opened-pound",
   "metadata": {},
   "outputs": [],
>>>>>>> parent of 29e74df (updated code)
   "source": [
    "Sourcecodes = flyprojection(Sourcesamples, Sourcekeys, ELEMENTS, k)\r\n",
    "Qian2016codes = flyprojection(Qian2016, Qian2016keys, ELEMENTS, k)\r\n",
    "Qian2018codes = flyprojection(Qian2018, Qian2018keys, ELEMENTS, k)\r\n",
    "QianU2019codes = flyprojection(QianU2019, QianU2019keys, ELEMENTS, k)\r\n",
    "QianR2019codes = flyprojection(QianR2019, QianR2019keys, ELEMENTS, k)\r\n",
    "\r\n",
    "#randomly project training and testing set\r\n",
    "Sourcesamples_trainingcodes = flyprojection(Sourcesamples_training, Sourcekeys, ELEMENTS, k)\r\n",
    "Sourcesamples_testingcodes = flyprojection(Sourcesamples_testing, Sourcekeys, ELEMENTS, k)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 13,
   "id": "exposed-gateway",
   "metadata": {},
   "outputs": [],
>>>>>>> parent of 29e74df (updated code)
   "source": [
    "#make an urbfugdust codes\r\n",
    "urbfugdustcodes = flyprojection([urbanfugdust], ['Urban fugitive dust'], ELEMENTS, k)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 18,
   "id": "comfortable-manchester",
   "metadata": {},
   "outputs": [],
>>>>>>> parent of 29e74df (updated code)
   "source": [
    "#save object\r\n",
    "def save_object(obj, filename):\r\n",
    "    with open(filename, 'wb') as output:  # Overwrites any existing file.\r\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "source": [
    "# Fit and store Model and Codes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "#save codes\r\n",
    "#save_object(Sourcecodes, 'models/revision_3/Sourcecodes_4.pkl')\r\n",
    "save_object(Sourcesamples_trainingcodes, 'models/multipleLDAmodels/Sourcesamples_trainingcodes_5.pkl')\r\n",
    "save_object(Sourcesamples_testingcodes, 'models/multipleLDAmodels/Sourcesamples_testingcodes_5.pkl')\r\n",
    "save_object(Qian2016codes, 'models/multipleLDAmodels/Qian2016codes_5.pkl')\r\n",
    "save_object(Qian2018codes, 'models/multipleLDAmodels/Qian2018codes_5.pkl')\r\n",
    "save_object(QianU2019codes, 'models/multipleLDAmodels/QianU2019codes_5.pkl')\r\n",
    "save_object(QianR2019codes, 'models/multipleLDAmodels/QianR2019codes_5.pkl')\r\n",
    "save_object(M, 'models/multipleLDAmodels/randommappingfeature.pkl')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "#save urb fug dust\r\n",
    "save_object(urbfugdustcodes, 'models/revision_3/Urbfugdustcodes_5.pkl')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Store dataframes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
=======
   "id": "specified-track",
   "metadata": {},
   "source": [
    "# Fit and store Model and Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "indonesian-edgar",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sourcesamples_trainingcodes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-26ed09bb21d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLatentDirichletAllocation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc_topic_prior\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmodel2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSourcesamples_trainingcodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Sourcesamples_trainingcodes' is not defined"
     ]
    }
   ],
   "source": [
    "#fit the Sourcecodes_training\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "model2 = LatentDirichletAllocation(n_components=20, doc_topic_prior = 0.01)\n",
    "\n",
    "model2 = model2.fit(Sourcesamples_trainingcodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "lyric-wesley",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model \n",
    "save_object(model2, 'models/revision_3/LDAModel_4.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "technical-garlic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save codes\n",
    "#save_object(Sourcecodes, 'models/revision_3/Sourcecodes_4.pkl')\n",
    "save_object(Sourcesamples_trainingcodes, 'models/multipleLDAmodels/Sourcesamples_trainingcodes_5.pkl')\n",
    "save_object(Sourcesamples_testingcodes, 'models/multipleLDAmodels/Sourcesamples_testingcodes_5.pkl')\n",
    "save_object(Qian2016codes, 'models/multipleLDAmodels/Qian2016codes_5.pkl')\n",
    "save_object(Qian2018codes, 'models/multipleLDAmodels/Qian2018codes_5.pkl')\n",
    "save_object(QianU2019codes, 'models/multipleLDAmodels/QianU2019codes_5.pkl')\n",
    "save_object(QianR2019codes, 'models/multipleLDAmodels/QianR2019codes_5.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "imperial-event",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save urb fug dust\n",
    "save_object(urbfugdustcodes, 'models/revision_3/Urbfugdustcodes_4.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "crude-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applylabels\n",
    "Qian2016, Qian2016prob =  applylabels(Qian2016, Qian2016keys, ELEMENTS, model2, Qian2016codes)\n",
    "Qian2018, Qian2018prob =  applylabels(Qian2018, Qian2018keys, ELEMENTS, model2, Qian2018codes)\n",
    "QianU2019, QianU2019prob =  applylabels(QianU2019, QianU2019keys, ELEMENTS, model2, QianU2019codes)\n",
    "QianR2019, QianR2019prob =  applylabels(QianR2019, QianR2019keys, ELEMENTS, model2, QianR2019codes)\n",
    "Sourcesamples, Sourcesamplesprob =  applylabels(Sourcesamples, Sourcekeys, ELEMENTS, model2, Sourcecodes)\n",
    "Sourcesamples_training, Sourcesamplesprob_training = applylabels(Sourcesamples_training, Sourcekeys, ELEMENTS, model2, Sourcesamples_trainingcodes)\n",
    "Sourcesamples_testing, Sourcesamplesprob_testing = applylabels(Sourcesamples_testing, Sourcekeys, ELEMENTS, model2, Sourcesamples_testingcodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "prime-amsterdam",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add urban fugitive dust\n",
    "Urbfugdust, Urbfugdustprob = applylabels([urbanfugdust], ['Urban fugitive dust'], ELEMENTS, model2, urbfugdustcodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-trader",
   "metadata": {},
   "source": [
    "# Store dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "authentic-canberra",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object([Qian2016, Qian2016prob, Qian2016keys], 'models/revision_3/Qian2016DF_4.pkl')\n",
    "save_object([Qian2018, Qian2018prob, Qian2018keys], 'models/revision_3/Qian2018DF_4.pkl')\n",
    "save_object([QianU2019, QianU2019prob, QianU2019keys], 'models/revision_3/QianU2019DF_4.pkl')\n",
    "save_object([QianR2019, QianR2019prob, QianR2019keys], 'models/revision_3/QianR2019DF_4.pkl')\n",
    "save_object([Sourcesamples, Sourcesamplesprob, Sourcekeys], 'models/revision_3/SourceDF_4.pkl')\n",
    "save_object([Sourcesamples_training, Sourcesamplesprob_training, Sourcekeys], 'models/revision_3/SourcetrainingDF_4.pkl')\n",
    "save_object([Sourcesamples_testing, Sourcesamplesprob_testing, Sourcekeys], 'models/revision_3/SourcetestingDF_4.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "average-police",
   "metadata": {},
   "outputs": [],
>>>>>>> parent of 29e74df (updated code)
   "source": [
    "#just the df\r\n",
    "save_object([Qian2016, Qian2016keys], 'models/multipleLDAmodels/Qian2016DF_5.pkl')\r\n",
    "save_object([Qian2018, Qian2018keys], 'models/multipleLDAmodels/Qian2018DF_5.pkl')\r\n",
    "save_object([QianU2019, QianU2019keys], 'models/multipleLDAmodels/QianU2019DF_5.pkl')\r\n",
    "save_object([QianR2019, QianR2019keys], 'models/multipleLDAmodels/QianR2019DF_5.pkl')\r\n",
    "save_object([Sourcesamples_training, Sourcekeys], 'models/multipleLDAmodels/SourcetrainingDF_5.pkl')\r\n",
    "save_object([Sourcesamples_testing, Sourcekeys], 'models/multipleLDAmodels/SourcetestingDF_5.pkl')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fiscal-wagon",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add urban fugitive dust\n",
    "save_object([Urbfugdust, Urbfugdustprob, ['Urban fugitive dust']], 'models/revision_3/UrbanfugdustDF_4.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinated-hearing",
   "metadata": {},
   "source": [
    "# Linking isotopes with LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "micro-divorce",
   "metadata": {},
   "outputs": [],
   "source": [
    "isotope_matrix = model2.components_ @ np.transpose(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "authentic-jerusalem",
   "metadata": {},
   "outputs": [],
   "source": [
    "isotope_DF = pd.DataFrame(isotope_matrix, columns = ELEMENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "expired-negative",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 48 artists>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(isotope_DF.columns, isotope_DF.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "sufficient-bryan",
   "metadata": {},
   "outputs": [],
   "source": [
    "element_ranks_list = []\n",
    "for i in np.arange(0, 30, 1):\n",
    "    element_ranks_list.append(isotope_DF.loc[i].sort_values(ascending = False)[0:10].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "utility-documentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(element_ranks_list).to_excel('models/revision_2/ranked_elements.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
=======
   "id": "numerical-second",
   "metadata": {},
>>>>>>> parent of 29e74df (updated code)
   "source": [
    "# LDA with different parameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
=======
   "execution_count": 19,
   "id": "hazardous-respondent",
   "metadata": {},
   "outputs": [],
>>>>>>> parent of 29e74df (updated code)
   "source": [
    "import itertools\r\n",
    "#fit the Sourcecodes_training\r\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 17,
=======
   "execution_count": 20,
   "id": "appropriate-connectivity",
   "metadata": {},
   "outputs": [],
>>>>>>> parent of 29e74df (updated code)
   "source": [
    "\r\n",
    "alpha = [0.0001, 0.001, 0.01, 0.1, 0.9]\r\n",
    "number_of_clusters = [5, 10, 15, 30, 50]\r\n",
    "\r\n",
    "for j,i in enumerate(itertools.product(alpha, number_of_clusters)):\r\n",
    "    model2 = LatentDirichletAllocation(n_components=i[1], doc_topic_prior = i[0])\r\n",
    "\r\n",
    "    model2 = model2.fit(Sourcesamples_trainingcodes)\r\n",
    "    #save model \r\n",
    "    save_object([i, model2], 'models/multipleLDAmodels/LDAModelvariant_' + str(j) + '.pkl')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "source": [],
=======
   "id": "organizational-representative",
   "metadata": {},
>>>>>>> parent of 29e74df (updated code)
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}